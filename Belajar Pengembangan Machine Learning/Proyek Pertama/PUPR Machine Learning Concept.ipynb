{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.25.2\n",
        "!pip install pandas==2.0.3\n",
        "!pip install scipy==1.13.1\n",
        "!pip install --upgrade gensim tensorflow #Upgrade gensim and tensorflow\n",
        "!pip install scikit-learn nltk imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "abyyY3Ex-L_E",
        "outputId": "6d6139a2-0c64-4c75-9de7-616289aff4ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a412185765304310bcb197d05939ee85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.0.3\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (2025.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.17.0)\n",
            "Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmA4V-Jz-NxN",
        "outputId": "a4f1dc97-4b8f-4acf-afe6-a462178b2553"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m651.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFUV1N-U9TGb",
        "outputId": "1edd06de-27d0-4c7b-dd40-b1bc782381fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PySastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8WXybPCDXg8",
        "outputId": "c3a59ac3-d0e0-4487-df23-150137c8e5f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PySastrawi in /usr/local/lib/python3.11/dist-packages (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devHiP_Q9E6L",
        "outputId": "0b6abb2f-4da9-4483-8b63-6cb71f41931d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from gensim.models import Word2Vec\n",
        "from Sastrawi.Stemmer import StemmerFactory\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi stemmer Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory # Correctly import StemmerFactory class\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Load kamus slang eksternal (misalnya dari nasalsabila/kamus-alay)\n",
        "slang_df = pd.read_csv('https://raw.githubusercontent.com/nasalsabila/kamus-alay/refs/heads/master/colloquial-indonesian-lexicon.csv')  # Unduh dari GitHub atau buat sendiri\n",
        "slang_dict = dict(zip(slang_df['slang'], slang_df['formal']))"
      ],
      "metadata": {
        "id": "_sUI1hbwC7KI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/miezlearning/Coding-Camp-2025/refs/heads/master/Belajar%20Pengembangan%20Machine%20Learning/data/hasil_review_genshin_impact.csv')\n",
        "print(\"Jumlah data:\", len(df))\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt98v3Ws9Gzs",
        "outputId": "9afd7e1e-c34a-4b34-850c-1803df53219f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data: 15000\n",
            "                               reviewId         userName  \\\n",
            "0  f70e716a-49a4-4c1a-a0d2-83e076f6bec0  Pengguna Google   \n",
            "1  020413b0-06ce-4bf1-81c1-3cbe97685507  Pengguna Google   \n",
            "2  2cc3ddee-9df3-4342-921b-5f436aa9cdf1  Pengguna Google   \n",
            "3  205af55a-bff1-49f4-8cb3-39123215e0c1  Pengguna Google   \n",
            "4  427ce1da-c883-4cfe-af5d-07dc71d5aa1f  Pengguna Google   \n",
            "\n",
            "                                           userImage  \\\n",
            "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "\n",
            "                                             content  score  thumbsUpCount  \\\n",
            "0                                menyenangkan sekali      5              0   \n",
            "1                                  Adventure Terbaik      5              0   \n",
            "2  yahh, meskipun handphone saya kentang masih bi...      5              0   \n",
            "3  developer hoyoverse gak ada otak. masak map mu...      1              0   \n",
            "4                   need gamepad support for Android      3              0   \n",
            "\n",
            "      reviewCreatedVersion                   at replyContent repliedAt  \\\n",
            "0  5.4.0_30057195_30231699  2025-03-24 01:25:03          NaN       NaN   \n",
            "1  5.4.0_30057195_30231699  2025-03-24 01:23:34          NaN       NaN   \n",
            "2  5.4.0_30057195_30231699  2025-03-24 01:01:45          NaN       NaN   \n",
            "3                      NaN  2025-03-24 00:54:19          NaN       NaN   \n",
            "4                      NaN  2025-03-24 00:09:56          NaN       NaN   \n",
            "\n",
            "                appVersion  \n",
            "0  5.4.0_30057195_30231699  \n",
            "1  5.4.0_30057195_30231699  \n",
            "2  5.4.0_30057195_30231699  \n",
            "3                      NaN  \n",
            "4                      NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pelabelan sentimen\n",
        "def label_sentiment(score):\n",
        "    if score <= 2: return 'negatif'\n",
        "    elif score == 3: return 'netral'\n",
        "    else: return 'positif'\n",
        "\n",
        "df['sentiment'] = df['score'].apply(label_sentiment)\n",
        "print(\"Distribusi awal:\\n\", df['sentiment'].value_counts().to_string())\n",
        "\n",
        "# Stopwords tambahan dari NLTK\n",
        "stop_words = set(stopwords.words('indonesian')) | {'dan', 'yang', 'di', 'ke', 'nya', 'ini', 'itu'}\n",
        "\n",
        "# Fungsi pembersihan teks yang lebih baik\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    # Pertahankan kata pendek yang relevan\n",
        "    text = ' '.join(slang_dict.get(word, word) for word in words if word not in stop_words or word in ['oke', 'bagus', 'top'])\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Oversampling dengan SMOTE setelah TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=10000, stop_words=list(stop_words), ngram_range=(1, 2))\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned_content']).toarray()\n",
        "y = pd.get_dummies(df['sentiment']).values\n",
        "smote = SMOTE(random_state=42)\n",
        "X_tfidf_smote, y_smote = smote.fit_resample(X_tfidf, np.argmax(y, axis=1))\n",
        "y_smote = pd.get_dummies(y_smote).values\n",
        "df_balanced = pd.DataFrame({'cleaned_content': [' '.join(doc) for doc in tfidf.inverse_transform(X_tfidf_smote)], 'sentiment': np.argmax(y_smote, axis=1)})\n",
        "df_balanced['sentiment'] = df_balanced['sentiment'].map({0: 'negatif', 1: 'netral', 2: 'positif'})\n",
        "print(f\"Jumlah data setelah SMOTE: {len(df_balanced)}\")\n",
        "print(\"Distribusi setelah SMOTE:\\n\", df_balanced['sentiment'].value_counts().to_string())\n",
        "\n",
        "# Fungsi evaluasi\n",
        "def evaluate_model(y_true, y_pred, set_name=\"\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\nAkurasi {set_name}: {accuracy * 100:.2f}%\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['negatif', 'netral', 'positif']))\n",
        "    return accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsWeAfs9G7B",
        "outputId": "8163335c-efe2-4901-efee-6876df280d8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi awal:\n",
            " sentiment\n",
            "positif    10101\n",
            "negatif     4001\n",
            "netral       898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data setelah SMOTE: 30303\n",
            "Distribusi setelah SMOTE:\n",
            " sentiment\n",
            "positif    10101\n",
            "negatif    10101\n",
            "netral     10101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Skema 1: Dense + TF-IDF (80/20) ---\n",
        "print(\"\\n=== Skema 1: Dense + TF-IDF (80/20) ===\")\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_tfidf_smote, y_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "model1 = Sequential([\n",
        "    Input(shape=(10000,)),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model1.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
        "model1.fit(X_train1, y_train1, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train1 = np.argmax(model1.predict(X_train1), axis=1)\n",
        "y_pred_test1 = np.argmax(model1.predict(X_test1), axis=1)\n",
        "y_train1_cat = np.argmax(y_train1, axis=1)\n",
        "y_test1_cat = np.argmax(y_test1, axis=1)\n",
        "train_acc1 = evaluate_model(y_train1_cat, y_pred_train1, \"Training\")\n",
        "test_acc1 = evaluate_model(y_test1_cat, y_pred_test1, \"Testing\")\n",
        "\n",
        "# --- Skema 2: LSTM + Word2Vec (80/20) ---\n",
        "print(\"\\n=== Skema 2: LSTM + Word2Vec (80/20) ===\")\n",
        "sentences = [text.split() for text in df_balanced['cleaned_content']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4, epochs=20)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(df_balanced['cleaned_content'])\n",
        "X_seq = tokenizer.texts_to_sequences(df_balanced['cleaned_content'])\n",
        "max_len = 100  # Dikurangi untuk teks pendek\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
        "\n",
        "embedding_matrix = np.zeros((10000, 200))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < 10000 and word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pad, y_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "model2 = Sequential([\n",
        "    Embedding(10000, 200, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
        "    Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=l2(0.005))),\n",
        "    LSTM(128),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.005)),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model2.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train2, y_train2, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train2 = np.argmax(model2.predict(X_train2), axis=1)\n",
        "y_pred_test2 = np.argmax(model2.predict(X_test2), axis=1)\n",
        "y_train2_cat = np.argmax(y_train2, axis=1)\n",
        "y_test2_cat = np.argmax(y_test2, axis=1)\n",
        "train_acc2 = evaluate_model(y_train2_cat, y_pred_train2, \"Training\")\n",
        "test_acc2 = evaluate_model(y_test2_cat, y_pred_test2, \"Testing\")\n",
        "\n",
        "# --- Skema 3: Dense + TF-IDF (70/30) ---\n",
        "print(\"\\n=== Skema 3: Dense + TF-IDF (70/30) ===\")\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_tfidf_smote, y_smote, test_size=0.3, random_state=42)\n",
        "\n",
        "model3 = Sequential([\n",
        "    Input(shape=(10000,)),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model3.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model3.fit(X_train3, y_train3, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train3 = np.argmax(model3.predict(X_train3), axis=1)\n",
        "y_pred_test3 = np.argmax(model3.predict(X_test3), axis=1)\n",
        "y_train3_cat = np.argmax(y_train3, axis=1)\n",
        "y_test3_cat = np.argmax(y_test3, axis=1)\n",
        "train_acc3 = evaluate_model(y_train3_cat, y_pred_train3, \"Training\")\n",
        "test_acc3 = evaluate_model(y_test3_cat, y_pred_test3, \"Testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTTvO7Do9HJG",
        "outputId": "479aa48d-cab3-4911-d976-353c218d3a46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Skema 1: Dense + TF-IDF (80/20) ===\n",
            "Epoch 1/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - accuracy: 0.5590 - loss: 1.3069 - val_accuracy: 0.7794 - val_loss: 0.8123 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.7482 - val_accuracy: 0.8247 - val_loss: 0.7553 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.6946 - val_accuracy: 0.8231 - val_loss: 0.7185 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.6357 - val_accuracy: 0.8487 - val_loss: 0.7048 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.6193 - val_accuracy: 0.8375 - val_loss: 0.6947 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.5860 - val_accuracy: 0.8219 - val_loss: 0.6815 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.5616 - val_accuracy: 0.8520 - val_loss: 0.6645 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.5413 - val_accuracy: 0.8346 - val_loss: 0.6923 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.5245 - val_accuracy: 0.8515 - val_loss: 0.6323 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.5136 - val_accuracy: 0.8561 - val_loss: 0.6319 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9085 - loss: 0.5019 - val_accuracy: 0.8602 - val_loss: 0.6204 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.4871 - val_accuracy: 0.8379 - val_loss: 0.6186 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9145 - loss: 0.4688 - val_accuracy: 0.8606 - val_loss: 0.5963 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.4657 - val_accuracy: 0.8660 - val_loss: 0.6010 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9145 - loss: 0.4480 - val_accuracy: 0.8742 - val_loss: 0.5815 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.4399 - val_accuracy: 0.8730 - val_loss: 0.5766 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.4414 - val_accuracy: 0.8689 - val_loss: 0.5771 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.4353 - val_accuracy: 0.8660 - val_loss: 0.5623 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9227 - loss: 0.4209 - val_accuracy: 0.8491 - val_loss: 0.5786 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9245 - loss: 0.4157 - val_accuracy: 0.8565 - val_loss: 0.5601 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.4170 - val_accuracy: 0.8660 - val_loss: 0.5604 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9236 - loss: 0.4046 - val_accuracy: 0.8664 - val_loss: 0.5445 - learning_rate: 5.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.4076 - val_accuracy: 0.8577 - val_loss: 0.5627 - learning_rate: 5.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9228 - loss: 0.3958 - val_accuracy: 0.8507 - val_loss: 0.5508 - learning_rate: 5.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.3689 - val_accuracy: 0.8788 - val_loss: 0.5147 - learning_rate: 1.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.3481 - val_accuracy: 0.8647 - val_loss: 0.5080 - learning_rate: 1.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.3337 - val_accuracy: 0.8680 - val_loss: 0.4959 - learning_rate: 1.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.3259 - val_accuracy: 0.8742 - val_loss: 0.5001 - learning_rate: 1.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.3182 - val_accuracy: 0.8623 - val_loss: 0.4909 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9381 - loss: 0.3177 - val_accuracy: 0.8577 - val_loss: 0.4925 - learning_rate: 1.0000e-04\n",
            "\u001b[1m758/758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "Akurasi Training: 93.72%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.94      0.93      0.94      8066\n",
            "      netral       0.91      0.96      0.94      8080\n",
            "     positif       0.97      0.92      0.94      8096\n",
            "\n",
            "    accuracy                           0.94     24242\n",
            "   macro avg       0.94      0.94      0.94     24242\n",
            "weighted avg       0.94      0.94      0.94     24242\n",
            "\n",
            "\n",
            "Akurasi Testing: 86.54%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.85      0.85      0.85      2035\n",
            "      netral       0.84      0.96      0.89      2021\n",
            "     positif       0.92      0.78      0.85      2005\n",
            "\n",
            "    accuracy                           0.87      6061\n",
            "   macro avg       0.87      0.87      0.86      6061\n",
            "weighted avg       0.87      0.87      0.86      6061\n",
            "\n",
            "\n",
            "=== Skema 2: LSTM + Word2Vec (80/20) ===\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.5473 - loss: 2.8946 - val_accuracy: 0.6095 - val_loss: 1.1684 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.6494 - loss: 1.0662 - val_accuracy: 0.6685 - val_loss: 0.9290 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.7014 - loss: 0.8549 - val_accuracy: 0.7357 - val_loss: 0.7768 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.7555 - loss: 0.7420 - val_accuracy: 0.7332 - val_loss: 0.7453 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.7914 - loss: 0.6601 - val_accuracy: 0.7984 - val_loss: 0.6427 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.8218 - loss: 0.5909 - val_accuracy: 0.8120 - val_loss: 0.6062 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.8427 - loss: 0.5426 - val_accuracy: 0.8041 - val_loss: 0.6223 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.8492 - loss: 0.5198 - val_accuracy: 0.8280 - val_loss: 0.5653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.8645 - loss: 0.4867 - val_accuracy: 0.8293 - val_loss: 0.5564 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.8700 - loss: 0.4688 - val_accuracy: 0.8363 - val_loss: 0.5180 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.8788 - loss: 0.4404 - val_accuracy: 0.8322 - val_loss: 0.5544 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.8844 - loss: 0.4284 - val_accuracy: 0.8421 - val_loss: 0.5443 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9005 - loss: 0.3731 - val_accuracy: 0.8685 - val_loss: 0.4600 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9138 - loss: 0.3312 - val_accuracy: 0.8701 - val_loss: 0.4681 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9168 - loss: 0.3123 - val_accuracy: 0.8738 - val_loss: 0.4571 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9189 - loss: 0.3053 - val_accuracy: 0.8722 - val_loss: 0.4595 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.9199 - loss: 0.2949 - val_accuracy: 0.8726 - val_loss: 0.4681 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9240 - loss: 0.2816 - val_accuracy: 0.8784 - val_loss: 0.4453 - learning_rate: 2.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9280 - loss: 0.2699 - val_accuracy: 0.8784 - val_loss: 0.4541 - learning_rate: 2.0000e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.9329 - loss: 0.2611 - val_accuracy: 0.8792 - val_loss: 0.4527 - learning_rate: 2.0000e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9327 - loss: 0.2628 - val_accuracy: 0.8816 - val_loss: 0.4531 - learning_rate: 1.0000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - accuracy: 0.9373 - loss: 0.2496 - val_accuracy: 0.8800 - val_loss: 0.4532 - learning_rate: 1.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.9374 - loss: 0.2492 - val_accuracy: 0.8788 - val_loss: 0.4558 - learning_rate: 1.0000e-05\n",
            "\u001b[1m758/758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step\n",
            "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Akurasi Training: 92.71%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.91      0.91      0.91      8066\n",
            "      netral       0.97      0.95      0.96      8080\n",
            "     positif       0.91      0.92      0.91      8096\n",
            "\n",
            "    accuracy                           0.93     24242\n",
            "   macro avg       0.93      0.93      0.93     24242\n",
            "weighted avg       0.93      0.93      0.93     24242\n",
            "\n",
            "\n",
            "Akurasi Testing: 87.74%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.85      0.85      0.85      2035\n",
            "      netral       0.92      0.94      0.93      2021\n",
            "     positif       0.86      0.84      0.85      2005\n",
            "\n",
            "    accuracy                           0.88      6061\n",
            "   macro avg       0.88      0.88      0.88      6061\n",
            "weighted avg       0.88      0.88      0.88      6061\n",
            "\n",
            "\n",
            "=== Skema 3: Dense + TF-IDF (70/30) ===\n",
            "Epoch 1/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.5512 - loss: 1.3455 - val_accuracy: 0.7606 - val_loss: 0.8193 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.7580 - val_accuracy: 0.7950 - val_loss: 0.7619 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.6815 - val_accuracy: 0.8280 - val_loss: 0.7451 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8667 - loss: 0.6400 - val_accuracy: 0.8313 - val_loss: 0.7098 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.6002 - val_accuracy: 0.8365 - val_loss: 0.7063 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8839 - loss: 0.5945 - val_accuracy: 0.8492 - val_loss: 0.6798 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.5658 - val_accuracy: 0.8417 - val_loss: 0.6672 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.5437 - val_accuracy: 0.8341 - val_loss: 0.6756 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9012 - loss: 0.5257 - val_accuracy: 0.8539 - val_loss: 0.6599 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.5094 - val_accuracy: 0.8544 - val_loss: 0.6457 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9105 - loss: 0.4963 - val_accuracy: 0.8530 - val_loss: 0.6441 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.4913 - val_accuracy: 0.8577 - val_loss: 0.6294 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9148 - loss: 0.4748 - val_accuracy: 0.8506 - val_loss: 0.6212 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.4632 - val_accuracy: 0.8365 - val_loss: 0.6388 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.4572 - val_accuracy: 0.8280 - val_loss: 0.6416 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.4335 - val_accuracy: 0.8586 - val_loss: 0.5823 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.3951 - val_accuracy: 0.8737 - val_loss: 0.5657 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9331 - loss: 0.3769 - val_accuracy: 0.8553 - val_loss: 0.5610 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.3689 - val_accuracy: 0.8563 - val_loss: 0.5548 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9327 - loss: 0.3676 - val_accuracy: 0.8501 - val_loss: 0.5498 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9335 - loss: 0.3597 - val_accuracy: 0.8699 - val_loss: 0.5357 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 0.3550 - val_accuracy: 0.8563 - val_loss: 0.5371 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9367 - loss: 0.3486 - val_accuracy: 0.8544 - val_loss: 0.5401 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.3434 - val_accuracy: 0.8558 - val_loss: 0.5339 - learning_rate: 2.0000e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.3371 - val_accuracy: 0.8558 - val_loss: 0.5355 - learning_rate: 2.0000e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9390 - loss: 0.3332 - val_accuracy: 0.8530 - val_loss: 0.5359 - learning_rate: 2.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9376 - loss: 0.3361 - val_accuracy: 0.8544 - val_loss: 0.5328 - learning_rate: 1.0000e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9394 - loss: 0.3301 - val_accuracy: 0.8582 - val_loss: 0.5290 - learning_rate: 1.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9384 - loss: 0.3273 - val_accuracy: 0.8553 - val_loss: 0.5320 - learning_rate: 1.0000e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m299/299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9391 - loss: 0.3261 - val_accuracy: 0.8544 - val_loss: 0.5312 - learning_rate: 1.0000e-05\n",
            "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "Akurasi Training: 93.75%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.94      0.93      0.94      7091\n",
            "      netral       0.91      0.97      0.94      7076\n",
            "     positif       0.97      0.91      0.94      7045\n",
            "\n",
            "    accuracy                           0.94     21212\n",
            "   macro avg       0.94      0.94      0.94     21212\n",
            "weighted avg       0.94      0.94      0.94     21212\n",
            "\n",
            "\n",
            "Akurasi Testing: 86.01%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.84      0.86      0.85      3010\n",
            "      netral       0.83      0.96      0.89      3025\n",
            "     positif       0.92      0.77      0.84      3056\n",
            "\n",
            "    accuracy                           0.86      9091\n",
            "   macro avg       0.86      0.86      0.86      9091\n",
            "weighted avg       0.86      0.86      0.86      9091\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi inference\n",
        "def predict_sentiment(text, model, vectorizer, is_word2vec=False, tokenizer=None, max_len=100):\n",
        "    cleaned_text = clean_text(text)\n",
        "    if is_word2vec:\n",
        "        seq = tokenizer.texts_to_sequences([cleaned_text])\n",
        "        padded = pad_sequences(seq, maxlen=max_len)\n",
        "        pred = model.predict(padded)\n",
        "    else:\n",
        "        tfidf_vec = vectorizer.transform([cleaned_text]).toarray()\n",
        "        pred = model.predict(tfidf_vec)\n",
        "    sentiment = np.argmax(pred, axis=1)[0]\n",
        "    return ['negatif', 'netral', 'positif'][sentiment]\n",
        "\n",
        "# Contoh inference\n",
        "sample_text = \"game nya bagus banget mantap\"\n",
        "print(\"\\nContoh Inference:\")\n",
        "print(f\"Skema 1 (Dense+TF-IDF): {predict_sentiment(sample_text, model1, tfidf)}\")\n",
        "print(f\"Skema 2 (LSTM+Word2Vec): {predict_sentiment(sample_text, model2, None, True, tokenizer, max_len)}\")\n",
        "print(f\"Skema 3 (Dense+TF-IDF): {predict_sentiment(sample_text, model3, tfidf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5eACFUk9HQ3",
        "outputId": "b7a79074-230e-4099-c93f-d426e78b67f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh Inference:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823ms/step\n",
            "Skema 1 (Dense+TF-IDF): positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
            "Skema 2 (LSTM+Word2Vec): positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
            "Skema 3 (Dense+TF-IDF): positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_balanced['sentiment'].value_counts().to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJWIhhcQ9HVd",
        "outputId": "dccfa687-1d4e-4ce8-850e-7f0b927a8edd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "positif    10101\n",
            "negatif    10101\n",
            "netral     10101\n"
          ]
        }
      ]
    }
  ]
}